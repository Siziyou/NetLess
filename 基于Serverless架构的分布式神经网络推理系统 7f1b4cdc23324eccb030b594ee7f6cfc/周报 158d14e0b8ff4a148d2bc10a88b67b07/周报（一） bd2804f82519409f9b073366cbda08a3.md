# 周报（一）

## dratf：

- 已完成openfaas的基础学习，并部署好所有的实验环境（本机伪分布式）
- 研究并确定pytorch的网络模型将以sequential为最小粒度进行拆分，并确定使用resnet系列（resnet18/50等）进行测试
- 正在学习openfaas的异步机制，需要学习相当量的外网资料
- 确定demo最终的目标是实现模型分布式的异步工作流

本周我完成了：

1、openfaas的学习和部署，openfaas需要利用faascli进行模板拉取、build、deploy三种命令，主要开发方式是利用handler文件实现，同时如果需要调用本地文件，就需要提前配置好dockerfile来封装好。并且完全部署了所有的实验环境：windows+wsl2+docker+k8s（single node）+openfaas。

2、研究了pytorch下网络模型的实现方式和pytorch tensor的数据处理办法。在多次尝试参数拆取和推理测试中，发现以Sequential为单位进行拆取不仅可以保留多层之间的参数完整性和特殊处理方法，尤其是以残差块为例，Sequential可以保证残差链接的完整性，如果内部再次分层拆取，就需要额外处理pytorch tensor来链接残差。因此最终还是确定了以Sequential为单位拆取。

拆掉所有的Sequential，还剩下前置的输入处理部分后后置的输出激活部分。因此这两部分将单独打包封装成Sequential。

基于此，我综合了实验难度和测试价值，选定使用Resnet家族进行实验。这样可以随着模型（参数量）规模的上升，体现出拆取对模型执行的影响和在openfaas中的通信成本。

3、单机部署，性能必然有所损失，如果不做优化处理，效率必然不如本机直接执行。因此在考察了诸多工作流机制后，如果能够实现异步化，那么即便是单节点部署，也可以依靠异步工作流，提高资源使用率，较之本机也有性能提升。因此正在学习openfaas的异步机制，这一过程预计需要几天的时间。

也正是因此，确定Demo的最终目标就是实现模型分布式的异步工作流。